import asyncio
import json
import os
import time
from http import HTTPStatus
from typing import List, Dict, Any, Tuple

import dashscope
from dotenv import load_dotenv
from langchain_community.chat_models import ChatTongyi
from langchain_core.prompts import ChatPromptTemplate
from pymilvus import MilvusClient

load_dotenv()


class Qwen25VLEmbedding:
    def __init__(self, api_key: str, model: str = os.getenv("AGENT1_EMBEDDING_MODEL"), is_print: str = True):
        """
        åˆå§‹åŒ–Qwen2.5-VLåµŒå…¥æ¨¡å‹
        """
        self.api_key = api_key
        self.model = model
        dashscope.api_key = api_key
        self.embedding_dim = 1024
        self.is_print = is_print

    def _print(self, *args, **kwargs):
        if self.is_print:
            print(*args, **kwargs)  # å¦‚æœå…è®¸æ‰“å°,å°±è°ƒç”¨å†…ç½®çš„ print

    async def embed_query(self, text: str) -> List[float]:
        """
        è¾“å…¥æ–‡æœ¬,è¾“å‡ºæ–‡æœ¬çš„å‘é‡ - å¼‚æ­¥ç‰ˆæœ¬
        """
        return await self._embed_text(text)

    async def _embed_text(self, text: str) -> List[float]:
        """
        æ–‡æœ¬å‘é‡åŒ–çš„å®ç°è¿‡ç¨‹,è°ƒç”¨qwen api - å¼‚æ­¥ç‰ˆæœ¬
        """
        try:
            # ä½¿ç”¨ asyncio.to_thread å°†åŒæ­¥çš„ SDK è°ƒç”¨è½¬ä¸ºå¼‚æ­¥
            resp = await asyncio.to_thread(
                dashscope.MultiModalEmbedding.call,
                model=self.model,
                input=[{'text': text}]
            )

            if resp.status_code == 200 and resp.output:
                return resp.output['embeddings'][0]['embedding']
            else:
                self._print(f"  è­¦å‘Š: æ–‡æœ¬åµŒå…¥å¤±è´¥: {resp.message}")
                return [0.0] * self.embedding_dim
        except Exception as e:
            self._print(f"  è­¦å‘Š: æ–‡æœ¬åµŒå…¥å¤±è´¥: {e}")
            return [0.0] * self.embedding_dim


class MultimodalRetriever:
    def __init__(
            self,
            embedding_model: Qwen25VLEmbedding,  # å¤šæ¨¡æ€åµŒå…¥æ¨¡å‹
            text_collection_name: str = "paper_text_collection",  # æ•°æ®åº“ä¸­æ–‡æœ¬é›†åˆçš„åç§°
            image_collection_name: str = "paper_image_collection",  # æ•°æ®åº“ä¸­å›¾ç‰‡é›†åˆçš„åç§°
            is_print: bool = True
    ):
        self.embedding_model = embedding_model
        self.text_collection_name = text_collection_name
        self.image_collection_name = image_collection_name
        self.qwen_api_key = os.getenv("TONGYI_API_KEY")
        self.is_print = is_print

        # è¿æ¥Milvus
        # Milvus Client é€šå¸¸æ˜¯åŒæ­¥çš„,æˆ‘ä»¬åœ¨å¼‚æ­¥æ–¹æ³•ä¸­ä½¿ç”¨ run_in_executor/to_thread æ¥é¿å…é˜»å¡
        self.milvus_client = MilvusClient(
            uri=os.getenv("ZILLIZ_ENDPOINT"),
            user=os.getenv("ZILLIZ_USER"),
            password=os.getenv("ZILLIZ_PASS")
        )

        # ä¸ºMQEå’ŒHyDEä½¿ç”¨ä¸åŒçš„æ¨¡å‹
        self.llm_MQE = ChatTongyi(
            model=os.getenv("AGENT1_MQE_MODEL"),
            api_key=os.getenv("TONGYI_API_KEY"),
            model_kwargs={"enable_thinking": False}  # ğŸ‘ˆ å…³é—­ thinking
        )
        self.llm_HyDE = ChatTongyi(
            model=os.getenv("AGENT1_HYDE_MODEL"),
            api_key=os.getenv("TONGYI_API_KEY"),
            model_kwargs={"enable_thinking": False}  # ğŸ‘ˆ å…³é—­ thinking
        )

    def _print(self, *args, **kwargs):
        if self.is_print:
            print(*args, **kwargs)  # å¦‚æœå…è®¸æ‰“å°,å°±è°ƒç”¨å†…ç½®çš„ print

    async def multi_query_expansion(self, query: str, num_queries: int = 3) -> List[str]:
        """
        å¤šæŸ¥è¯¢æ‰©å±•(MQE) - å¼‚æ­¥ç‰ˆæœ¬
        Args:
            query: åŸå§‹æŸ¥è¯¢
            num_queries: ç”Ÿæˆçš„æŸ¥è¯¢æ•°é‡
        Returns:
            æ‰©å±•åçš„æŸ¥è¯¢åˆ—è¡¨(åŒ…å«åŸå§‹æŸ¥è¯¢)
        """
        prompt = ChatPromptTemplate.from_template(
            """You are an AI assistant that helps users generate multiple search queries.
            For the given user question, generate {num} different but related search queries from various perspectives.
            These queries should help find relevant information.

            Original question: {question}

            Return only the list of queries, one per line, without numbering or any other formatting."""
        )

        messages = prompt.format_messages(question=query, num=num_queries)
        # ä½¿ç”¨ ainvoke è¿›è¡Œå¼‚æ­¥è°ƒç”¨
        response = await self.llm_MQE.ainvoke(messages)
        # è§£æç”Ÿæˆçš„æŸ¥è¯¢
        expanded_queries = [q.strip() for q in response.content.strip().split('\n') if q.strip()]
        # ç¡®ä¿åŒ…å«åŸå§‹æŸ¥è¯¢
        all_queries = [query] + expanded_queries[:num_queries]
        return all_queries

    async def hypothetical_document_embedding(self, query: str) -> str:
        """
        å‡è®¾æ–‡æ¡£åµŒå…¥(HyDE) - å¼‚æ­¥ç‰ˆæœ¬
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
        Returns:
            ç”Ÿæˆçš„å‡è®¾æ–‡æ¡£
        """
        prompt = ChatPromptTemplate.from_template(
            """Based on the following question, generate a hypothetical, detailed answer document.
            This document should contain technical details and relevant information that could answer the question.

            Question: {question}

            Please generate a professional, detailed answer (100-200 words):"""
        )
        messages = prompt.format_messages(question=query)
        # ä½¿ç”¨ ainvoke è¿›è¡Œå¼‚æ­¥è°ƒç”¨
        response = await self.llm_HyDE.ainvoke(messages)
        return response.content.strip()

    async def search_collection(
            self,
            query_embedding: List[float],
            collection_name: str,
            partition_name: str,
            top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        åœ¨æŒ‡å®šé›†åˆå’Œåˆ†åŒºä¸­æœç´¢ - å¼‚æ­¥ç‰ˆæœ¬
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            collection_name: é›†åˆåç§°
            partition_name: åˆ†åŒºåç§°
            top_k: è¿”å›ç»“æœæ•°é‡
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if collection_name == self.text_collection_name:
            vector_field = "text_embedding"
        else:
            vector_field = "image_embedding"

        # ä½¿ç”¨ asyncio.to_thread å°†åŒæ­¥çš„ Milvus æœç´¢è½¬ä¸ºå¼‚æ­¥
        results = await asyncio.to_thread(
            self.milvus_client.search,
            collection_name=collection_name,
            data=[query_embedding],
            anns_field=vector_field,
            search_params={"metric_type": "COSINE"},
            limit=top_k,
            partition_names=[partition_name],
            output_fields=["*"]
        )
        return results[0] if results else []

    async def _process_single_query_async(self, q: str, partition_name: str, top_k: int) -> Tuple[List, List]:
        """
        å†…éƒ¨è¾…åŠ©å‡½æ•°:å¤„ç†å•ä¸ªæŸ¥è¯¢å­—ç¬¦ä¸²çš„å®Œæ•´æ£€ç´¢æµç¨‹(Embedding -> Milvus Search)
        """
        # 1. ç”Ÿæˆå‘é‡ (ç°åœ¨ embed_query å·²ç»æ˜¯å¼‚æ­¥çš„)
        query_embedding = await self.embedding_model.embed_query(q)

        # 2. å¹¶è¡Œæœç´¢ Text å’Œ Image é›†åˆ (search_collection ç°åœ¨ä¹Ÿæ˜¯å¼‚æ­¥çš„)
        text_results, image_results = await asyncio.gather(
            self.search_collection(
                query_embedding=query_embedding,
                collection_name=self.text_collection_name,
                partition_name=partition_name,
                top_k=top_k
            ),
            self.search_collection(
                query_embedding=query_embedding,
                collection_name=self.image_collection_name,
                partition_name=partition_name,
                top_k=top_k
            )
        )

        return text_results, image_results

    async def retrieve(
            self,
            query: str,
            partition_name: str,
            use_mqe: bool = True,
            use_hyde: bool = True,
            top_k: int = 10,
            image_top_k: int = None
    ) -> Dict[str, List[Dict[str, Any]]]:
        """
        æ‰§è¡Œæ£€ç´¢ - å¼‚æ­¥ç‰ˆæœ¬
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            partition_name: åˆ†åŒºåç§° (dahua, hik, uniview)
            use_mqe: æ˜¯å¦ä½¿ç”¨å¤šæŸ¥è¯¢æ‰©å±•
            use_hyde: æ˜¯å¦ä½¿ç”¨å‡è®¾æ–‡æ¡£åµŒå…¥
            top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„æ–‡æœ¬ç»“æœæ•°é‡
            image_top_k: æ¯ä¸ªæŸ¥è¯¢è¿”å›çš„å›¾ç‰‡ç»“æœæ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨top_kçš„ä¸€åŠ
        Returns:
            åŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡æ£€ç´¢ç»“æœçš„å­—å…¸
        """
        # è®¾ç½®å›¾ç‰‡æ£€ç´¢æ•°é‡ï¼Œé»˜è®¤ä¸ºæ–‡æœ¬çš„ä¸€åŠ
        if image_top_k is None:
            image_top_k = max(1, top_k // 2)
        all_queries = []

        self._print("\n" + "=" * 40)
        self._print("ç¬¬ä¸€æ­¥:ç”ŸæˆæŸ¥è¯¢æ‹“å±•(MQE)å’Œå‡è®¾æ–‡æ¡£åµŒå…¥(HyDE)")
        self._print("=" * 40)

        # ä½¿ç”¨ asyncio.gather å¹¶è¡Œæ‰§è¡Œ MQE å’Œ HyDE
        tasks = []

        # 1. å¤šæŸ¥è¯¢æ‰©å±•ä»»åŠ¡
        if use_mqe:
            self._print("å¼‚æ­¥è°ƒç”¨LLM:æ‰§è¡Œå¤šæŸ¥è¯¢æ‰©å±•...")
            tasks.append(self.multi_query_expansion(query, num_queries=5))
        else:
            # å¦‚æœä¸ä½¿ç”¨MQE,æˆ‘ä»¬éœ€è¦ä¿æŒåˆ—è¡¨ç»“æ„å¯¹é½,è¿™é‡Œæ‰‹åŠ¨æ·»åŠ åŸå§‹æŸ¥è¯¢
            all_queries.append(query)
            tasks.append(asyncio.sleep(0))  # å ä½ç¬¦,ä¿æŒç´¢å¼•ä¸€è‡´æ€§é€»è¾‘ç®€å•åŒ–

        # 2. å‡è®¾æ–‡æ¡£åµŒå…¥ä»»åŠ¡
        if use_hyde:
            self._print("å¼‚æ­¥è°ƒç”¨LLM :ç”Ÿæˆå‡è®¾æ–‡æ¡£...")
            tasks.append(self.hypothetical_document_embedding(query))

        # æ‰§è¡Œç¬¬ä¸€æ­¥çš„æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
        if tasks:
            results = await asyncio.gather(*tasks)

            # å¤„ç†ç»“æœ
            idx = 0
            if use_mqe:
                all_queries.extend(results[idx])
                idx += 1
            else:
                idx += 1  # è·³è¿‡å ä½ç¬¦

            if use_hyde:
                all_queries.append(results[idx])

        # 3. å¯¹æ‰€æœ‰æŸ¥è¯¢è¿›è¡Œæ£€ç´¢
        text_results_all = []  # åœ¨æ–‡æœ¬é›†åˆä¸­çš„æŸ¥è¯¢ç»“æœ
        image_results_all = []  # åœ¨å›¾ç‰‡é›†åˆä¸­çš„æŸ¥è¯¢ç»“æœ

        self._print("\n" + "=" * 40)
        self._print("ç¬¬äºŒæ­¥:æŸ¥è¯¢æ‰€æœ‰ç”Ÿæˆçš„å­—æ®µ")
        self._print("=" * 40)

        # æ‰¹é‡å¤„ç†æŸ¥è¯¢åµŒå…¥ä»¥å‡å°‘APIè°ƒç”¨æ¬¡æ•°
        query_embeddings = await asyncio.gather(*[self.embedding_model.embed_query(q) for q in all_queries])

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢çš„æ£€ç´¢æ“ä½œ
        search_tasks = []
        for i, q in enumerate(all_queries):
            self._print(f"å¹¶å‘æ‰§è¡Œ:æŸ¥è¯¢æ£€ç´¢: {q[:10]}...")
            query_embedding = query_embeddings[i]

            # ç›´æ¥å¹¶è¡Œæœç´¢ä¸¤ä¸ªé›†åˆï¼Œä½¿ç”¨ä¸åŒçš„top_k
            text_search_task = self.search_collection(
                query_embedding=query_embedding,
                collection_name=self.text_collection_name,
                partition_name=partition_name,
                top_k=top_k
            )
            image_search_task = self.search_collection(
                query_embedding=query_embedding,
                collection_name=self.image_collection_name,
                partition_name=partition_name,
                top_k=image_top_k
            )

            search_tasks.append(asyncio.gather(text_search_task, image_search_task))

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢çš„ æ£€ç´¢
        if search_tasks:
            search_results_list = await asyncio.gather(*search_tasks)

            for t_res, i_res in search_results_list:
                text_results_all.extend(t_res)
                image_results_all.extend(i_res)

        self._print("\n" + "=" * 40)
        self._print("ç¬¬ä¸‰æ­¥:æŸ¥è¯¢ç»“æœå»é‡æ’åºä¸æˆªæ–­")
        self._print("=" * 40)

        # 4. å»é‡å¹¶æŒ‰åˆ†æ•°æ’åº
        # æ³¨æ„:æ­¤å¤„ç»´æŒåŒæ­¥æ‰§è¡Œã€‚
        # åŸå› :å»é‡æ’åºæ˜¯çº¯å†…å­˜CPUæ“ä½œ(å­—å…¸æŸ¥æ‰¾å’Œåˆ—è¡¨æ’åº),æ•°æ®é‡çº§è¾ƒå°(<1000æ¡)ã€‚
        # åœ¨Python GILé™åˆ¶ä¸‹,ä½¿ç”¨async/awaitæˆ–å¤šçº¿ç¨‹å¤„ç†CPUå¯†é›†å‹ä»»åŠ¡å¹¶ä¸ä¼šå¸¦æ¥æ€§èƒ½æå‡,
        # åè€Œå¯èƒ½å› ä¸Šä¸‹æ–‡åˆ‡æ¢å¢åŠ å¼€é”€ã€‚
        text_results_unique = self._deduplicate_results(text_results_all, "chunk_id")
        self._print(f"1.å¯¹æ–‡æœ¬æ£€ç´¢ç»“æœè¿›è¡Œå»é‡ã€æ’åº (CPUå¯†é›†å‹ä»»åŠ¡,ä¿æŒåŒæ­¥)")
        image_results_unique = self._deduplicate_results(image_results_all, "image_id")
        self._print(f"2.å¯¹å›¾ç‰‡æ£€ç´¢ç»“æœè¿›è¡Œå»é‡ã€æ’åº (CPUå¯†é›†å‹ä»»åŠ¡,ä¿æŒåŒæ­¥)")
        self._print(f"3.ç»Ÿä¸€æˆªæ–­,æ–‡æœ¬ä¿ç•™å¾—åˆ†æœ€é«˜çš„{top_k * 2}æ¡è®°å½•,å›¾ç‰‡ä¿ç•™å¾—åˆ†æœ€é«˜çš„{image_top_k * 2}æ¡è®°å½•")

        return {  # ç”±äºç”Ÿæˆäº† n ä¸ªç›¸å…³çš„æŸ¥è¯¢å­—æ®µ(MQEå’ŒHyDE),æ‰€ä»¥ä¼šæŸ¥è¯¢ n * top_kä¸ªæ–‡æœ¬å’Œ n * image_top_kä¸ªå›¾ç‰‡å‡ºæ¥
            "text_results": text_results_unique[:top_k * 2],
            "image_results": image_results_unique[:image_top_k * 2]
        }

    def _deduplicate_results(
            self,
            results: List[Dict[str, Any]],
            id_field: str
    ) -> List[Dict[str, Any]]:
        """
        å»é‡å¹¶ä¿ç•™æœ€é«˜åˆ†æ•°çš„ç»“æœ
        Args:
            results: åŸå§‹ç»“æœåˆ—è¡¨
            id_field: ç”¨äºå»é‡çš„IDå­—æ®µ
        Returns:
            å»é‡åçš„ç»“æœåˆ—è¡¨
        """
        seen = {}
        for result in results:
            result_id = result['entity'].get(id_field)
            score = result.get('distance', 0)
            if result_id not in seen or score > seen[result_id].get('distance', 0):
                seen[result_id] = result
        # æŒ‰åˆ†æ•°æ’åº
        unique_results = list(seen.values())
        unique_results.sort(key=lambda x: x.get('distance', 0), reverse=True)
        return unique_results

    async def rerank(
            self,
            query: str,
            documents: List[str],
            top_n: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼çš„Qwen3-Rerankè¿›è¡Œé‡æ’åº - å¼‚æ­¥ç‰ˆæœ¬
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: å¾…é‡æ’åºçš„æ–‡æ¡£åˆ—è¡¨
            top_n: è¿”å›å‰Nä¸ªç»“æœ
        Returns:
            é‡æ’åºåçš„ç»“æœåˆ—è¡¨,æ ¼å¼: [{'index': int, 'relevance_score': float}, ...]
        """
        try:
            # ä½¿ç”¨ asyncio.to_thread å°†åŒæ­¥çš„ API è°ƒç”¨è½¬ä¸ºå¼‚æ­¥
            resp = await asyncio.to_thread(
                dashscope.TextReRank.call,
                model=os.getenv("AGENT1_RERANK_MODEL"),
                query=query,
                documents=documents,
                top_n=min(top_n, len(documents)),
                return_documents=True
            )

            if resp.status_code == HTTPStatus.OK:
                # è§£æè¿”å›ç»“æœ
                results = []
                for item in resp.output.results:
                    results.append({
                        'index': item.index,
                        'relevance_score': item.relevance_score
                    })
                return results
            else:
                self._print(f"é‡æ’åºå¤±è´¥: {resp.code} - {resp.message}")
                return []
        except Exception as e:
            self._print(f"é‡æ’åºå¤±è´¥: {e}")
            return []

    async def retrieve_and_rerank(
            self,
            query: str,
            partition_name: str,
            use_mqe: bool = True,
            use_hyde: bool = True,
            top_k: int = 10,
            rerank_top_n: int = 5,
            image_top_k: int = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ£€ç´¢å’Œé‡æ’åºçš„å®Œæ•´æµç¨‹ - å¼‚æ­¥ç‰ˆæœ¬
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            partition_name: åˆ†åŒºåç§°
            use_mqe: æ˜¯å¦ä½¿ç”¨å¤šæŸ¥è¯¢æ‰©å±•
            use_hyde: æ˜¯å¦ä½¿ç”¨å‡è®¾æ–‡æ¡£åµŒå…¥
            top_k: åˆå§‹æ–‡æœ¬æ£€ç´¢æ•°é‡
            rerank_top_n: é‡æ’åºåè¿”å›æ•°é‡
            image_top_k: åˆå§‹å›¾ç‰‡æ£€ç´¢æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨top_kçš„ä¸€åŠ
        Returns:
            åŒ…å«é‡æ’åºåçš„æ–‡æœ¬å’Œå›¾ç‰‡ç»“æœ
        """
        # 1. æ£€ç´¢ (Await å¼‚æ­¥æ£€ç´¢æ–¹æ³•)
        results = await self.retrieve(
            query=query,
            partition_name=partition_name,
            use_mqe=use_mqe,
            use_hyde=use_hyde,
            top_k=top_k,
            image_top_k=image_top_k
        )

        self._print("\n" + "=" * 40)
        self._print("ç¬¬å››æ­¥:å¯¹æŸ¥è¯¢ç»“æœè¿›è¡Œé‡æ’åº")
        self._print("=" * 40)

        # å‡†å¤‡æ–‡æœ¬é‡æ’åºæ•°æ®
        text_docs = []
        text_metadata = []
        for result in results['text_results']:
            entity = result['entity']
            text_docs.append(entity.get('text', ''))
            text_metadata.append({
                'chunk_id': entity.get('chunk_id'),
                'page_numbers': entity.get('page_numbers'),
                'has_images': entity.get('has_images'),
                'image_paths': entity.get('image_paths'),
                'metadata': entity.get('metadata'),
                'original_score': result.get('distance', 0)
            })

        # å‡†å¤‡å›¾ç‰‡é‡æ’åºæ•°æ®
        image_docs = []
        image_metadata = []
        for result in results['image_results']:
            entity = result['entity']
            # ä½¿ç”¨æ–‡æœ¬ä¸Šä¸‹æ–‡ä½œä¸ºé‡æ’åºçš„æ–‡æœ¬
            image_docs.append(entity.get('text_context', ''))
            image_metadata.append({
                'image_id': entity.get('image_id'),
                'image_path': entity.get('image_path'),  # æœ¬åœ°è·¯å¾„
                'page_numbers': entity.get('page_numbers'),
                'text_context': entity.get('text_context'),
                'metadata': entity.get('metadata'),
                'original_score': result.get('distance', 0)
            })

        # å¼‚æ­¥å¹¶å‘æ‰§è¡Œé‡æ’åº (rerank ç°åœ¨ä¹Ÿæ˜¯å¼‚æ­¥çš„)
        self._print(f"å¹¶å‘æ‰§è¡Œ:å¯¹æ–‡æœ¬å’Œå›¾ç‰‡çš„æ£€ç´¢ç»“æœè¿›è¡Œé‡æ’åº...")

        # å®šä¹‰ä»»åŠ¡
        rerank_text_task = self.rerank(query, text_docs, top_n=rerank_top_n) if text_docs else asyncio.sleep(0)
        rerank_image_task = self.rerank(query, image_docs, top_n=rerank_top_n) if image_docs else asyncio.sleep(0)

        # ç­‰å¾…ç»“æœ
        rerank_text_results, rerank_image_results = await asyncio.gather(rerank_text_task, rerank_image_task)

        # å¤„ç†æ–‡æœ¬ç»“æœ
        reranked_text = []
        if text_docs and isinstance(rerank_text_results, list):
            for rr in rerank_text_results:
                idx = rr['index']
                reranked_text.append({
                    'text': text_docs[idx],
                    'rerank_score': rr['relevance_score'],
                    **text_metadata[idx]
                })

        # å¤„ç†å›¾ç‰‡ç»“æœ
        reranked_images = []
        if image_docs and isinstance(rerank_image_results, list):
            for rr in rerank_image_results:
                idx = rr['index']
                reranked_images.append({
                    'rerank_score': rr['relevance_score'],
                    **image_metadata[idx]
                })

        self._print("\n" + "=" * 40)
        self._print("ç¬¬äº”æ­¥:å®Œæˆæ£€ç´¢è¿‡ç¨‹")
        self._print("=" * 40)
        self._print(f"æ–‡æœ¬ç»“æœ: {len(reranked_text)}ä¸ª\nå›¾ç‰‡ç»“æœ: {len(reranked_images)}ä¸ª")

        # æ”¶é›†éœ€è¦çš„å±æ€§
        text_set = set()
        image_path_set = set()

        # å¤„ç†æ–‡æœ¬ç»“æœ
        for item in reranked_text:
            text = item.get('text')
            if text and isinstance(text, str):
                text_set.add(text.strip())

            # å¦‚æœ has_images ä¸º true,æ”¶é›† ['metadata']['image_path']
            if item.get('has_images'):
                metadata_dict = json.loads(item.get('metadata'))
                if isinstance(metadata_dict, dict):
                    image_path = metadata_dict.get('image_paths')[0]
                    if image_path and isinstance(image_path, str):
                        image_path_set.add(image_path.strip())

        # å¤„ç†å›¾ç‰‡ç»“æœ
        for item in reranked_images:
            text_context = item.get('text_context')
            if text_context and isinstance(text_context, str):
                text_set.add(text_context.strip())

            # æ”¶é›† ['image_path']
            image_path = item.get('image_path')
            if image_path and isinstance(image_path, str):
                image_path_set.add(image_path.strip())

        return {
            'text': list(text_set),
            'image_path': list(image_path_set)
        }


# ==================== åˆ›å»ºæ£€ç´¢å·¥å…·å¹¶è¿”å› ====================
def create_retrieval_tool(api_key: str = None, is_print: bool = False):
    """
    åˆ›å»ºæ£€ç´¢å·¥å…·çš„å·¥å‚å‡½æ•°
    Args:
        api_key: é€šä¹‰åƒé—®APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è·å–
        is_print: æ˜¯å¦æ‰“å°è°ƒè¯•ä¿¡æ¯
    Returns:
        é…ç½®å¥½çš„æ£€ç´¢å·¥å…·å‡½æ•°
    """
    import json
    from langchain_core.tools import tool

    if api_key is None:
        api_key = os.getenv("TONGYI_API_KEY")

    # åˆ›å»ºæ£€ç´¢å™¨å®ä¾‹
    retriever = MultimodalRetriever(
        embedding_model=Qwen25VLEmbedding(
            api_key=api_key,
            model=os.getenv("AGENT1_EMBEDDING_MODEL")
        ),
        is_print=is_print
    )

    @tool
    async def retrieve_tool(
            query: str,
            partition_name: str,
            use_mqe: bool = True,
            use_hyde: bool = True,
            top_k: int = 5,
            rerank_top_n: int = 3
    ) -> str:
        """
        Perform multimodal retrieval using the retriever.
        First retrieves candidate documents from the specified partition using the user query.
        Optionally enables MQE (Multi-Query Expansion) and HyDE (Hypothetical Document Embeddings) for improved recall.
        Then uses a reranker to reorder and return the top `rerank_top_n` most relevant document contents.

        Args:
            query (str): Retrieval query text. Should be clear and specific for optimal results.
            partition_name (str): Data partition name. Must be one of: "transformer", "lora", or "dpo".
            use_mqe (bool): Whether to enable Multi-Query Expansion. Default is True.
                            Enabling this improves recall but increases retrieval time. It is recommended to disable this for simple queries to save latency.
            use_hyde (bool): Whether to enable Hypothetical Document Embeddings. Default is True.
                            Enabling this improves recall but increases retrieval time. It is recommended to disable this for simple queries to save latency.
            top_k (int): Initial retrieval candidate document count. Default is 5.
                         Increasing this value can help when results are not ideal, but it will increase retrieval time.
            rerank_top_n (int): Number of documents to return after reranking. Default is 3.
                                A value between 3 and 5 is recommended to balance precision and speed.

        Returns:
            str: JSON-formatted string containing text content and image paths.
        """
        try:
            result = await retriever.retrieve_and_rerank(
                query=query,
                partition_name=partition_name,
                use_mqe=use_mqe,
                use_hyde=use_hyde,
                top_k=top_k,
                rerank_top_n=rerank_top_n
            )
            # Return JSON format for easy parsing
            return json.dumps({
                "text": result.get("text", "No relevant text found"),
                "image_paths": result.get("image_path", [])
            }, ensure_ascii=False)
        except Exception as e:
            return json.dumps({
                "error": f"Retrieval failed: {str(e)}",
                "text": "",
                "image_paths": []
            }, ensure_ascii=False)

    return retrieve_tool


if __name__ == "__main__":
    async def main():
        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = MultimodalRetriever(
            embedding_model=Qwen25VLEmbedding(
                api_key=os.getenv("TONGYI_API_KEY"),
                model=os.getenv("AGENT1_EMBEDDING_MODEL")
            ),
            is_print=False
        )

        start_time = time.time()

        # æ‰§è¡Œæ£€ç´¢å’Œé‡æ’åº (å¼‚æ­¥ç­‰å¾…)
        results = await retriever.retrieve_and_rerank(
            query="How to calculate the multi-head attention mechanism in Transformer",
            partition_name="transformer",
            use_mqe=True,
            use_hyde=True,
            top_k=5,
            rerank_top_n=3
        )

        end_time = time.time()
        print(f"\næ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

        # æ‰“å°ç»“æœ - æ›´æ–°ä¸ºæ–°çš„è¿”å›ç»“æ„
        print("\n" * 2 + "=" * 40)
        print("æ”¶é›†çš„æ–‡æœ¬å†…å®¹")
        print("=" * 40)
        if results['text']:
            for i, text in enumerate(results['text'], 1):
                clean_text = text.replace('\n', ' ').strip()
                print(f"ğŸ“Š {i}. {clean_text[:50]}..." if len(clean_text) > 50 else f"ğŸ“Š {i}. {clean_text}")
        else:
            print("æ²¡æœ‰æ”¶é›†åˆ°æ–‡æœ¬å†…å®¹")

        print("\n" * 2 + "=" * 40)
        print("æ”¶é›†çš„å›¾ç‰‡è·¯å¾„")
        print("=" * 40)
        if results['image_path']:
            for i, image_path in enumerate(results['image_path'], 1):
                print(f"ğŸ–¼ï¸ {i}. {image_path}")
        else:
            print("æ²¡æœ‰æ”¶é›†åˆ°å›¾ç‰‡è·¯å¾„")


    # è¿è¡Œå¼‚æ­¥ä¸»å¾ªç¯
    asyncio.run(main())
